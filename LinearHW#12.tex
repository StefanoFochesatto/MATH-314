%%% Preamble starts here.
\documentclass{amsart}
%for the heading
\usepackage{fancyhdr, enumerate}
%for the picture. 
\usepackage{tikz}
%adjust the page width
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{epstopdf}

\linespread{1.1}

%special commands for number sets
\def\RR{{\mathbb R}}
\def\NN{{\mathbb N}}
\def\ZZ{{\mathbb Z}}
\def\QQ{{\mathbb Q}}
\def\CC{{\mathbb C}}
\def\PP{{\mathbb P}}

\makeatletter
\newcommand{\vo}{\vec{o}\@ifnextchar{^}{\,}{}}
\makeatother

% header
\lhead{\sc  Linear Algebra: Homework 12}
\chead{\sc Stefano Fochesatto } 
\rhead{\today}
\cfoot{}
\pagestyle{fancy}

%%%% Main document starts here.

\begin{document}
\thispagestyle{fancy}





{\huge\textbf{Section 6.6:}}\\\\
%%%first problem
\noindent\textbf{Exercise 6.6.4: } Find the equation $y = b_0 + b_1x$ of the last squares line that best fits the given data points. $(2,3), (3,2), (5,1), (6,0)$.\\\\
\noindent \textbf{Solution: } First we want to construct the Design matrix, and observation vector given our data. Consider the following,
\begin{equation*}
X = 
\begin{bmatrix}
 1 &   2   \\
 1 &    3  \\
 1 &   5 \\
 1& 6
\end{bmatrix}
,
y = 
\begin{bmatrix}
3\\
2\\
1\\
0
\end{bmatrix}
\end{equation*}
Now that we have the parameters for our linear model, $y  = Xb + e$ where $b$ is our parameter vector and $e$ is our residual vector. Our goal is to minimize $e$, which means we need to find the least squares solution to $Xb = y$. From Theorem 14 the least squares solution $b$ is given by $X^TXb = X^Ty$. Through some matrix algebra,
\begin{equation*}
X^TX = \begin{bmatrix}1&1&1&1\\ \:\:2&3&5&6\end{bmatrix}\begin{bmatrix}\:1\:&\:\:\:2\:\:\:\\ \:\:1\:&\:\:\:\:3\:\:\\ \:\:1\:&\:\:\:5\:\\ \:\:1&\:6\end{bmatrix}
 = 
\begin{bmatrix}4&16\\ 16&74\end{bmatrix}
\end{equation*}
\begin{equation*}
X^Ty =  \begin{bmatrix}1&1&1&1\\ \:\:2&3&5&6\end{bmatrix}\begin{bmatrix}
3\\
2\\
1\\
0
\end{bmatrix} = \begin{bmatrix}6\\ 17\end{bmatrix}
\end{equation*}
Now we have the following equation,
\begin{equation*}
\begin{bmatrix}4&16\\ 16&74\end{bmatrix}\begin{bmatrix}b_0\\ b_1\end{bmatrix} = \begin{bmatrix}6\\ 17\end{bmatrix}
\end{equation*}
The fastest way to solve this system is to find ${X^TX}^{-1}$ and then multiplying both sides. Using the 2 x 2 inverse formula,
\begin{equation*}
b = \{X^TX\}^{-1}X^Ty
\end{equation*}
\begin{equation*}
\{X^TX\}^{-1} = \frac{1}{40}\begin{bmatrix}74&-16\\ -16&4\end{bmatrix}
\end{equation*}
Therefore, by substitution,
\begin{align*}
b &= \frac{1}{40}\begin{bmatrix}74&-16\\ -16&4\end{bmatrix}\begin{bmatrix}6\\ 17\end{bmatrix}\\
&= \begin{bmatrix}\frac{43}{10}\\ -\frac{7}{10}\end{bmatrix}
\end{align*}
Therefore we know that the line $y = \frac{43}{10} - \frac{7}{10}x$ is the best fit for our data.

\vspace{1in}



%%%second problem
\noindent\textbf{Exercise 6.6.8: }A simple curve that often makes a good model for variable costs of a company, as a function of the sales level $x$, has the form $y = b_1x + b_2x^2 + b_3x^3$. There is not constant term because fixed costs are not included.\\\\
\begin{enumerate}

\item Give the design matrix and the parameter vector for the linear model that leads to a least - square fit of the equation above, with data $(x_1,y_1),...,(x_n,y_n)$\\
\noindent \textbf{Solution: } The design matrix for the given data and the desired model is,
\begin{equation*}
X = 
\begin{bmatrix} 
   x_{1} & x_{1}^2 & x_{1}^3\\
    \vdots & \vdots &   \vdots\\
    x_{n} &   x_{n}^2  &  x_{n}^3
    \end{bmatrix}
\end{equation*}
We can see that the parameter vector is gonna be,
\begin{equation*}
b = 
\begin{bmatrix}
 b_1 \\
  b_2  \\
b_3 
\end{bmatrix}
\end{equation*}
The next step would be to find the least - squares solution for $y = Xb + e$ where $y$ is the observation vector or,
\begin{equation*}
y = 
\begin{bmatrix}
 y_1 \\
  \vdots \\
y_n 
\end{bmatrix}
\end{equation*}
and $e$ is the residual vector (we want to minimize this).
\vspace{1in}


\item \{MATLAB\} Find the least - squares curve of the form above to fit the data $(4,1.58)$, $(6,2.08)$, $(8 , 2.5)$, $(10, 2.8)$, $(12,3.1)$, $(14,3.4)$, $(16,3.8)$ and, $(18, 4.32)$ with the values in the thousands. If possible, produce a graph that shows and the graph of the cubic approximation.\\
\noindent \textbf{Solution: } First we want to set up the design matrix $X$, and the observation vector $y$. Plugging into the matrix in part a,
\begin{equation*}
X = 
\begin{bmatrix}
4  & 16  & 64  \\
6  &  36 &   216\\
 8 &  64 &   512\\
 10 & 100  &   1000\\
12  & 144  &  1728\\
14  &  196 &   2744\\
 16 &  256 &   4096\\
 18 &  324 &  5832 
\end{bmatrix}, 
y = 
\begin{bmatrix}
1.58  \\
2.08  \\ 
 2.5 \\
 2.8 \\ 
3.1  \\ 
3.4  \\  
 3.8 \\  
4.32 
\end{bmatrix}
\end{equation*}
From Matlab we get,
\begin{equation*}
b = \{X^TX\}^{-1}X^Ty =
\begin{bmatrix}
0.5132  \\
-0.03348 \\ 
 0.001016 
\end{bmatrix}
\end{equation*}

\begin{figure}
\centering
        \includegraphics[totalheight=8cm]{../../image2.png}
            \label{figure 1: Graph of LLS}
\end{figure}
\vspace{1in}
\end{enumerate}

{\huge\textbf{Section 6.7:}}\\\\
%%%first problem
\noindent\textbf{Exercise 6.7.14: }Let $T$ be a one-to-one linear transformation from a vector space $V$ into $R^n$. Show that for $u$, $v$ in $V$, the formula $<u,v> = T(u)T(v)$ defines an inner product on $V$\\
\noindent \textbf{Solution: }
\begin {enumerate}

\item Suppose $u$, $v$ in $V$ then,
\begin{align*}
<u,v> &= T(u)T(v) \text{ (by definition of inner product)} \\
&= T(v)T(u) \text{ (because $T(v), T(u) \in R^n$ and is commutative) } \\
&= <v,u>
\end{align*}
\vspace{.25in}


\item Suppose $u$, $v$ and $w$ in $V$ then,
\begin{align*}
<u+w,v> &= T(u+w)T(v) \text{ (by definition of inner product)} \\
&= \{T(u)+T(w)\}T(v) \text{ (linear transformations respect vector addition) } \\
&= T(u)T(v)+T(w)T(v)\\
&= <u,v> + <w,v>
\end{align*}
\vspace{.25in}


\item Suppose $u$, $v$ in $V$ and $c$ in $R$ then,
\begin{align*}
<cu,v> &= T(cu)T(v) \text{ (by definition of inner product)} \\
&= cT(u)T(v) \text{ (linear transformations respect multiplication by scalars) } \\
&= c<u,v>
\end{align*}
\vspace{.25in}


\item Suppose $u$ in $V$ then,
\begin{align*}
<u,u> &= T(u)T(u) \text{ (by definition of inner product)} \\
&= T(u)^2
\end{align*}
From here we can see that any vector in $R^n$ when its squared will be larger than or equal to the 0 vector.\\
\vspace{.25in}


\end{enumerate}

%%%second problem
\noindent\textbf{Exercise 6.7.18: } Use the inner product axioms to verify the statement,
\begin{equation*}
||u+v||^2 + ||u-v||^2 = 2||u||^2+2||v||^2 
\end{equation*}
\noindent \textbf{Solution: } Suppose,
\begin{align*}
||u+v||^2 + ||u-v||^2 &= <u+v,u+v>+<u-v,u-v> \text{(by definition of a norm)}\\
&= <u,u>+<v,v>+<u,v> + <v+u> + <u,u> + <v,v> - <u,v> - <v,u> \text{}\\
&\text{(expanding by inner product axiom 2)}\\
&= 2<u,u> +2<v,v>\\
&= 2||u||^2+2||v||^2 
\end{align*}
\vspace{1in}



%%%third problem
\noindent\textbf{Exercise 6.7.22: } Refer to $V = C[0,1]$, with the inner product given by an integral. Compute $<f,g>$, where $f(t) = 5t - 3$ and $g(t) = t^3 - t^2$\\ 
\noindent \textbf{Solution: }By simply computing the inner product, by the given definitions we get,
\begin{align*}
<f,g> &= \int_{0}^{1} (5t - 3)(t^3 - t^2)dt\\
&= \int_{0}^{1} 5t^4-8t^3+3t^2 dt\\
&= {t^5-2t^4+t^3}|_{0}^{1}\\
&=1-2+1 = 0
\end{align*}

\vspace{1in}





\end{document}